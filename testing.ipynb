{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from network.cnn_definition_paper import rgb255_to_obj_net \n",
    "from keras.layers import Lambda\n",
    "\n",
    "from xnp.xnp_tf_layers import MtMCreation, MtMEvaluation\n",
    "from reverse_op import PODestarisation\n",
    "\n",
    "from data_handling.model_info import load_model_info\n",
    "from data_handling import DataLoader\n",
    "\n",
    "bop_path  = '/tf/notebooks/datasets'\n",
    "dataset = 'tless'\n",
    "dataset_path = f'{bop_path}/{dataset}'\n",
    "\n",
    "print(f'Dataset path:   {dataset_path}')\n",
    "print(f'GPUs Available: {tf.config.list_physical_devices(\"GPU\")}')\n",
    "\n",
    "results_path = '/results/'\n",
    "\n",
    "foreign_info = 'scene_maskrcnn_detections_syn+real_info.json'\n",
    "\n",
    "test = ['test_primesense']\n",
    "\n",
    "xyDim = 112\n",
    "strides = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def totuplething(x1, x2, x4, x7):\n",
    "    return ((x1, x2, x4, x7), x7)\n",
    "\n",
    "for oiu in range(1,2):\n",
    "    model_info = load_model_info(dataset_path, oiu, verbose=1)\n",
    "\n",
    "    trained_cnn = tf.keras.models.load_model(f'{dataset_path}/saved_models/csl_o{oiu}_trainable_layers')\n",
    "\n",
    "    rgb_input, depth_input, cam_K, coord_K = trained_cnn.inputs\n",
    "    star_representation, dash_representation, w_px, w_d, seg = trained_cnn.outputs\n",
    "\n",
    "    segmentation = Lambda(lambda x: tf.cast(x>0.75, x.dtype))(seg)\n",
    "    w_px = Lambda(lambda x: x[0][...,tf.newaxis,:] * x[1][...,tf.newaxis])([w_px, segmentation])\n",
    "    w_d = Lambda(lambda x: x[0][...,tf.newaxis,:] * x[1][...,tf.newaxis])([w_d, segmentation])\n",
    "\n",
    "    po_image = PODestarisation(model_info,amount_of_instances = 1)(star_representation, dash_representation, segmentation)\n",
    "    po_image = Lambda(lambda x: x[0][...,tf.newaxis,:] * x[1][...,tf.newaxis])([po_image, segmentation])\n",
    "    MtM = MtMCreation(\"po\", strides)((po_image, w_px, cam_K, coord_K))\n",
    "    pred_T_, pred_Omega = MtMEvaluation()(MtM)\n",
    "\n",
    "    depth = Lambda(lambda x: x[:,::strides,::strides])(depth_input)\n",
    "    MtM_d = MtMCreation(\"depth\")((po_image, depth , w_d))\n",
    "    pred_T_d, pred_Omega = MtMEvaluation()(tf.keras.layers.Add()([MtM, MtM_d]))\n",
    "\n",
    "    pred_model = tf.keras.Model(trained_cnn.inputs, (pred_T_, pred_T_d))\n",
    "\n",
    "    test_foreign_data = DataLoader.load_foreign_data([f'{dataset_path}/{d}' for d in test ], foreign_info, oiu)\n",
    "    print(f'Found TEST foreign data for {len(test_foreign_data)} occurencies of object {oiu}, where {len([d for d in test_foreign_data if \"primesense\" in d[\"root\"]])} origined from primesense.')\n",
    "\n",
    "    res = pred_model.predict(DataLoader.Dataset(test_foreign_data,xyDim, test_mode=True).batch(1).prefetch(20).map(totuplething), verbose=1)\n",
    "\n",
    "    rowwisestr = 'scene_id,im_id,obj_id,score,R,t,time\\n'\n",
    "    rowwisestr_d = 'scene_id,im_id,obj_id,score,R,t,time\\n'\n",
    "    for tdi, td in enumerate(test_foreign_data):\n",
    "        pose_ = res[0][tdi][0]\n",
    "        pose_d = res[1][tdi][0]\n",
    "        rowwisestr += f'{int(td[\"root\"][-6:])},{int(td[\"file_name\"])},{oiu},0.5,{\" \".join(list(pose_[:3,:3].flatten().astype(str)))},{\" \".join(list(pose_[:3,3].flatten().astype(str)))},-1\\n'\n",
    "        rowwisestr_d += f'{int(td[\"root\"][-6:])},{int(td[\"file_name\"])},{oiu},0.5,{\" \".join(list(pose_d[:3,:3].flatten().astype(str)))},{\" \".join(list(pose_d[:3,3].flatten().astype(str)))},-1\\n'\n",
    "    \n",
    "    f = open(f\"{results_path}/new-paper-{oiu}-cosypose-frame-rgb_tless-test.csv\",\"w\")\n",
    "    f.write(rowwisestr)\n",
    "    f.close()\n",
    "\n",
    "    f = open(f\"{results_path}/new-paper-{oiu}-cosypose-frame-rgb-d_tless-test.csv\",\"w\")\n",
    "    f.write(rowwisestr_d)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = 'scene_id,im_id,obj_id,score,R,t,time\\n'\n",
    "for oiu in range(1,31):\n",
    "    f = open(f\"{results_path}/new-paper-{oiu}-cosypose-frame-rgb_tless-test.csv\",\"r\")\n",
    "    combined_results += f.read()[len('scene_id,im_id,obj_id,score,R,t,time\\n'):]\n",
    "    f.close()\n",
    "    \n",
    "f = open(f\"{results_path}/new-paper-1-30-cosypose-frame-rgb_tless-test.csv\",\"w\")\n",
    "f.write(combined_results)\n",
    "f.close()\n",
    "\n",
    "combined_results = 'scene_id,im_id,obj_id,score,R,t,time\\n'\n",
    "for oiu in range(1,31):\n",
    "    f = open(f\"{results_path}/new-paper-{oiu}-cosypose-frame-rgb-d_tless-test.csv\",\"r\")\n",
    "    combined_results += f.read()[len('scene_id,im_id,obj_id,score,R,t,time\\n'):]\n",
    "    f.close()\n",
    "    \n",
    "f = open(f\"{results_path}/new-paper-1-30-cosypose-frame-rgb-d_tless-test.csv\",\"w\")\n",
    "f.write(combined_results)\n",
    "f.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
