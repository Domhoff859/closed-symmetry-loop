{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_handling.model_info import load_model_info\n",
    "from data_handling import DataLoader, Conversion_Layers\n",
    "from network import loss, cnn_definition_paper\n",
    "from star_representation import StarRepresentation\n",
    "from dash_repesentation import RemoveCameraEffect, DashRepresentation\n",
    "from reverse_op import PODestarisation\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the dataset and its path\n",
    "dataset = 'tless'\n",
    "dataset_path = f'{dataset}'\n",
    "\n",
    "# Define the train and test data\n",
    "train = ['train_primesense', 'train_pbr']\n",
    "test = ['test_primesense']\n",
    "\n",
    "# Define the dimensions and strides\n",
    "xyDim = 112\n",
    "strides = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a custom loss function\n",
    "def pred_loss(true, pred):\n",
    "    return pred\n",
    "\n",
    "# Define a helper function\n",
    "def totuplething(x1, x2, x3, x4, x5, x6, x7):\n",
    "    return ((x1, x2, x3, x4, x7, x5, x6), x6)\n",
    "\n",
    "# Loop over a range of values\n",
    "for oiu in range(1,30):\n",
    "    print('Object ', oiu)\n",
    "\n",
    "    # Load model information\n",
    "    model_info = load_model_info(dataset_path, oiu, verbose=1)\n",
    "\n",
    "    # Load train data\n",
    "    train_data = DataLoader.load_gt_data([f'{dataset_path}/{d}' for d in train ], oiu)\n",
    "    print(f'Found train data for {len(train_data)} occurencies of object {oiu}, where {len([d for d in train_data if \"primesense\" in d[\"root\"]])} origined from primesense.')\n",
    "\n",
    "    # Set the device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create the inputs and valid_po tensors\n",
    "    inputs, valid_po, isvalid, depth, segmentation = Conversion_Layers.create_Dataset_conversion_layers(xyDim, xyDim, model_info, strides)\n",
    "\n",
    "    # Create the valid_dash and valid_po_star tensors\n",
    "    valid_dash = DashRepresentation(model_info[\"symmetries_discrete\"][0][:3,-1] / 2. if len(model_info[\"symmetries_discrete\"]) > 0 else 0 )(inputs['roationmatrix'], valid_po)\n",
    "    valid_po_star = StarRepresentation(model_info)(valid_po)\n",
    "\n",
    "    # Define the CNN layers\n",
    "    cnn_po_star, cnn_po_dash, cnn_w_px, cnn_w_d, cnn_seg = cnn_definition_paper.rgb255_to_obj_net(inputs['rgb'])\n",
    "    dash_image = RemoveCameraEffect(strides)(cnn_po_dash, inputs['camera_matrix'], inputs['coord_offset'])\n",
    "\n",
    "    # Create the csl_trainable_layers module\n",
    "    csl_trainable_layers = nn.Module([inputs['rgb'], inputs['depth'], inputs['camera_matrix'], inputs['coord_offset']],\n",
    "                                      [cnn_po_star, dash_image, cnn_w_px, cnn_w_d, cnn_seg])\n",
    "\n",
    "    # Perform PODestarisation\n",
    "    po_image = PODestarisation(model_info,amount_of_instances = 1)(cnn_po_star, dash_image, isvalid, inputs['roationmatrix'])\n",
    "    po_uv, po_cam = loss.Po_to_Img()(po_image, inputs['camera_matrix'], inputs['roationmatrix'], inputs['translation'])\n",
    "\n",
    "    # Calculate the differences and losses\n",
    "    diff_postar = loss.AvgSqrDiff_of_validPixels(name='pos_diff')(cnn_po_star, valid_po_star, isvalid)\n",
    "    diff_vo = loss.AvgSqrDiff_of_validPixels(name='vo_diff')(dash_image, valid_dash, isvalid)\n",
    "    (seg_loss, seg_met, seg_fgmet) = loss.Seg_Loss(name='seg')(cnn_seg, segmentation)  \n",
    "\n",
    "    sig2inv = loss.ToOmega()(cnn_w_px, isvalid)\n",
    "    po_uv_diff = loss.UV_diff(strides)(po_uv, inputs['coord_offset'])\n",
    "    lw2_loss, chi2error = loss.Avg_nllh(name='w2')(sig2inv, po_uv_diff, isvalid)\n",
    "\n",
    "    sig1inv =  loss.ToOmega()(cnn_w_d, isvalid)\n",
    "    po_depth_diff = loss.D_diff()(po_cam, depth)\n",
    "    lw1_loss, chi2error_d = loss.Avg_nllh(name='w1')(sig1inv, po_depth_diff, isvalid)\n",
    "\n",
    "    # Create the train_povoseg_model and train_model modules\n",
    "    train_povoseg_model = nn.ModuleList([inputs.values(), (diff_postar, diff_vo, seg_loss, seg_met, seg_fgmet)])\n",
    "    train_model = nn.ModuleList([inputs.values(), (diff_postar, diff_vo, seg_loss, seg_met, seg_fgmet,\n",
    "                                                  lw2_loss, chi2error, lw1_loss, chi2error_d)])\n",
    "\n",
    "    # Move the modules to the device\n",
    "    train_povoseg_model.to(device)\n",
    "    train_model.to(device)\n",
    "\n",
    "    # Define the optimizers\n",
    "    optimizer_povoseg = optim.Adam(train_povoseg_model.parameters(), lr=0.0001, amsgrad=True)\n",
    "    optimizer_model = optim.Adam(train_model.parameters(), lr=0.0001, amsgrad=True)\n",
    "\n",
    "    # Define the criterion (loss function)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop for train_povoseg_model\n",
    "    for epoch in range(2):\n",
    "        train_povoseg_model.train()\n",
    "        for data in DataLoader.Dataset(train_data, xyDim, times=2, group_size=5, random=True).batch(80).prefetch(20).map(totuplething):\n",
    "            inputs, targets = data\n",
    "            inputs = [input.to(device) for input in inputs]\n",
    "            targets = [target.to(device) for target in targets]\n",
    "\n",
    "            optimizer_povoseg.zero_grad()\n",
    "            outputs = train_povoseg_model(*inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer_povoseg.step()\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(train_povoseg_model.state_dict(), f'{dataset_path}/saved_weights/new_{oiu}_train_povoseg_2e')\n",
    "\n",
    "    # Training loop for train_model\n",
    "    for epoch in range(10):\n",
    "        train_model.train()\n",
    "        for data in DataLoader.Dataset(train_data, xyDim, times=2, group_size=5, random=True).batch(40).prefetch(20).map(totuplething):\n",
    "            inputs, targets = data\n",
    "            inputs = [input.to(device) for input in inputs]\n",
    "            targets = [target.to(device) for target in targets]\n",
    "\n",
    "            optimizer_model.zero_grad()\n",
    "            outputs = train_model(*inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer_model.step()\n",
    "\n",
    "    # Save the trained models\n",
    "    torch.save(train_model.state_dict(), f'{dataset_path}/saved_weights/csl_o{oiu}_train_model_10e')\n",
    "    torch.save(csl_trainable_layers.state_dict(), f'{dataset_path}/saved_models/csl_o{oiu}_trainable_layers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
